{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !pip install --upgrade pip\\n!pip install llama-index-core==0.10.50\\n!pip install llama-index-readers-file==0.1.25\\n!pip install llama-index-llms-nvidia==0.1.3\\n!pip install llama-index-embeddings-nvidia==0.1.4\\n!pip install llama-index-postprocessor-nvidia-rerank==0.1.2\\n!pip install ipywidgets==8.1.3 '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" !pip install --upgrade pip\n",
    "!pip install llama-index-core==0.10.50\n",
    "!pip install llama-index-readers-file==0.1.25\n",
    "!pip install llama-index-llms-nvidia==0.1.3\n",
    "!pip install llama-index-embeddings-nvidia==0.1.4\n",
    "!pip install llama-index-postprocessor-nvidia-rerank==0.1.2\n",
    "!pip install ipywidgets==8.1.3 \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.nvidia import NVIDIA\n",
    "\n",
    "llm = NVIDIA(\n",
    "  model=\"meta/llama-3.1-405b-instruct\",\n",
    "  api_key=\"\", \n",
    "  temperature=0.3,\n",
    "  top_p=0.6,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id=\"zjkBMFhNj_g\"\n",
    "with open(f\"Youtube_ID={video_id}.txt\",\"r\") as f:\n",
    "    txt=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"\"\"<context>{txt}</context>\n",
    "Focus on the video script given between <context><context> tags.You have to understand what this video was abot and then create Multiple choice Q&A.\n",
    "The Q&A should be such that it will test the knowledge of human who has watched the video,keep in mind to use only the context to generate MCQs. \n",
    "Generate 5 such MCQs.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_answer=llm.complete(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the video script, I've created 5 multiple-choice questions to test the knowledge of a human who has watched the video. Here they are:\n",
      "\n",
      "**Q1: What is the primary function of a large language model, according to the speaker?**\n",
      "\n",
      "A) To generate images and videos\n",
      "B) To predict the next word in a sequence\n",
      "C) To summarize long documents\n",
      "D) To translate languages\n",
      "\n",
      "**Answer: B) To predict the next word in a sequence**\n",
      "\n",
      "**Q2: What is the name of the large language model released by Meta AI, which is considered one of the most powerful open-source models?**\n",
      "\n",
      "A) Llama 2 Series\n",
      "B) GPT Series\n",
      "C) CLA Series\n",
      "D) BART Series\n",
      "\n",
      "**Answer: A) Llama 2 Series**\n",
      "\n",
      "**Q3: What is the process called when a large language model is fine-tuned on a specific dataset to become an expert in a particular task?**\n",
      "\n",
      "A) Pre-training\n",
      "B) Fine-tuning\n",
      "C) Self-improvement\n",
      "D) Customization\n",
      "\n",
      "**Answer: B) Fine-tuning**\n",
      "\n",
      "**Q4: What is the name of the attack that involves adding a specific suffix to a prompt to \"jailbreak\" a large language model and make it respond in an undesirable way?**\n",
      "\n",
      "A) Prompt injection attack\n",
      "B) Data poisoning attack\n",
      "C) Universal transferable suffix attack\n",
      "D) Jailbreak attack\n",
      "\n",
      "**Answer: C) Universal transferable suffix attack**\n",
      "\n",
      "**Q5: According to the speaker, what is the analogy used to describe the emerging operating system based on large language models?**\n",
      "\n",
      "A) A chatbot\n",
      "B) A word generator\n",
      "C) A kernel process coordinating resources for problem-solving\n",
      "D) A desktop operating system\n",
      "\n",
      "**Answer: C) A kernel process coordinating resources for problem-solving**\n"
     ]
    }
   ],
   "source": [
    "print(llm_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Demo_MCQ.txt\",\"w\") as f:\n",
    "    f.write(str(llm_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"\"\"<context>{txt}</context>\n",
    "Focus on the video script given between <context><context> tags.You have to understand what this video was about and then identify the main topics that the was talked in the lecture.\n",
    "Topics should be such that the provided video script can be divided easily under those topics.Make sure Topics are not ambiguous and do have some meaninful segregation of content.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_answer=llm.complete(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Topic_division.txt\",\"w\") as f:\n",
    "    f.write(str(llm_answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvidia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
